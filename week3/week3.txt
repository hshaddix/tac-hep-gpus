// Code Written by Hayden Shaddix 
// Acessible at the Github: https://github.com/hshaddix/tac-hep-gpus/blob/main/week3/

// Exercise 1

#include <stdio.h>
#include <cuda_runtime.h>

const int DSIZE = 40960;        // Size of vectors
const int block_size = 256;     // Block size
const int grid_size = DSIZE / block_size; // Grid size

__global__ void vector_swap(float *A, float *B, int size) {
    // Calculate the global index of the thread
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    // Swap elements if index is within bounds
    if (idx < size) {
        float temp = A[idx];
        A[idx] = B[idx];
        B[idx] = temp;
    }
}

int main() {
    float *h_A, *h_B, *d_A, *d_B;

    // Allocate host memory
    h_A = new float[DSIZE];
    h_B = new float[DSIZE];

    // Initialize vectors A and B
    for (int i = 0; i < DSIZE; i++) {
        h_A[i] = rand() / (float)RAND_MAX;  // Random values between 0 and 1
        h_B[i] = rand() / (float)RAND_MAX;  // Random values between 0 and 1
    }

    // Print a few elements before the swap
    printf("Before Swap:\n");
    printf("A[0] = %f, B[0] = %f\n", h_A[0], h_B[0]);
    printf("A[DSIZE-1] = %f, B[DSIZE-1] = %f\n", h_A[DSIZE-1], h_B[DSIZE-1]);

    // Allocate device memory
    cudaMalloc((void**)&d_A, DSIZE * sizeof(float));
    cudaMalloc((void**)&d_B, DSIZE * sizeof(float));

    // Copy data from host to device
    cudaMemcpy(d_A, h_A, DSIZE * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_B, h_B, DSIZE * sizeof(float), cudaMemcpyHostToDevice);

    // Launch the kernel for swapping
    vector_swap<<<grid_size, block_size>>>(d_A, d_B, DSIZE);

    // Copy back the swapped data from device to host
    cudaMemcpy(h_A, d_A, DSIZE * sizeof(float), cudaMemcpyDeviceToHost);
    cudaMemcpy(h_B, d_B, DSIZE * sizeof(float), cudaMemcpyDeviceToHost);

    // Print a few elements after the swap
    printf("\nAfter Swap:\n");
    printf("A[0] = %f, B[0] = %f\n", h_A[0], h_B[0]);
    printf("A[DSIZE-1] = %f, B[DSIZE-1] = %f\n", h_A[DSIZE-1], h_B[DSIZE-1]);

    // Free host and device memory
    delete[] h_A;
    delete[] h_B;
    cudaFree(d_A);
    cudaFree(d_B);

    return 0;
}
// Exercise 2 

#include <stdio.h>
#include <cuda_runtime.h>

const int DSIZE_X = 256; // Matrix width (M)
const int DSIZE_Y = 256; // Matrix height (N)

// Kernel to add two matrices
__global__ void add_matrix(float *A, float *B, float *C, int width, int height)
{
    // Calculate 2D index using thread and block indices
    int idx = blockIdx.x * blockDim.x + threadIdx.x; // Column index
    int idy = blockIdx.y * blockDim.y + threadIdx.y; // Row index

    // Convert the 2D index [i,j] into a 1D index: [i * width + j]
    int index = idy * width + idx;

    // Add the two matrices if the index is within bounds
    if (idx < width && idy < height) {
        C[index] = A[index] + B[index];
    }
}

int main()
{
    // Matrix sizes
    int matrix_size = DSIZE_X * DSIZE_Y;
    int mem_size = matrix_size * sizeof(float);

    // Host memory allocation
    float *h_A = new float[matrix_size];
    float *h_B = new float[matrix_size];
    float *h_C = new float[matrix_size];

    // Initialize matrices with some values
    for (int i = 0; i < DSIZE_Y; i++) {
        for (int j = 0; j < DSIZE_X; j++) {
            int index = i * DSIZE_X + j;
            h_A[index] = rand() / (float)RAND_MAX;  // Random values between 0 and 1
            h_B[index] = rand() / (float)RAND_MAX;  // Random values between 0 and 1
            h_C[index] = 0;  // Initialize result matrix to 0
        }
    }

    // Device memory allocation
    float *d_A, *d_B, *d_C;
    cudaMalloc((void**)&d_A, mem_size);
    cudaMalloc((void**)&d_B, mem_size);
    cudaMalloc((void**)&d_C, mem_size);

    // Copy data from host to device
    cudaMemcpy(d_A, h_A, mem_size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_B, h_B, mem_size, cudaMemcpyHostToDevice);

    // Define block size and grid size
    dim3 blockSize(16, 16); // 16x16 threads per block
    dim3 gridSize((DSIZE_X + blockSize.x - 1) / blockSize.x, (DSIZE_Y + blockSize.y - 1) / blockSize.y); // Ensure complete coverage of the matrix

    // Launch the kernel
    add_matrix<<<gridSize, blockSize>>>(d_A, d_B, d_C, DSIZE_X, DSIZE_Y);

    // Copy back the result from device to host
    cudaMemcpy(h_C, d_C, mem_size, cudaMemcpyDeviceToHost);

    // Verify by printing a few elements
    printf("A[0] + B[0] = %f + %f = %f\n", h_A[0], h_B[0], h_C[0]);
    printf("A[DSIZE_X-1] + B[DSIZE_X-1] = %f + %f = %f\n", h_A[DSIZE_X-1], h_B[DSIZE_X-1], h_C[DSIZE_X-1]);

    // Free memory
    delete[] h_A;
    delete[] h_B;
    delete[] h_C;
    cudaFree(d_A);
    cudaFree(d_B);
    cudaFree(d_C);

    return 0;
}
// Exercise 3 

#include <stdio.h>
#include <time.h>
#include <cuda_runtime.h>

const int DSIZE = 256;        // Size of the NxN matrix
const float A_val = 3.0f;     // Constant for matrix A
const float B_val = 2.0f;     // Constant for matrix B

// Error checking macro
#define cudaCheckErrors(msg)                                   \
   do {                                                        \
       cudaError_t __err = cudaGetLastError();                 \
       if (__err != cudaSuccess) {                             \
           fprintf(stderr, "Fatal error: %s (%s at %s:%d)\n",  \
                   msg, cudaGetErrorString(__err),             \
                   __FILE__, __LINE__);                        \
           fprintf(stderr, "*** FAILED - ABORTING\n");         \
           exit(1);                                            \
       }                                                       \
   } while (0)

// Print a matrix (for debugging/verification)
void print_matrix(const float *matrix, int size, int blockSize) {
    printf("\nMatrix:\n");
    for (int i = 0; i < blockSize; i++) {
        for (int j = 0; j < blockSize; j++) {
            printf("%f ", matrix[i * size + j]);
        }
        printf("\n");
    }
    printf("\n");
}

// Square matrix multiplication on CPU : C = A * B
void matrix_mul_cpu(const float *A, const float *B, float *C, int size) {
    for (int i = 0; i < size; i++) {
        for (int j = 0; j < size; j++) {
            float temp = 0;
            for (int k = 0; k < size; k++) {
                temp += A[i * size + k] * B[k * size + j]; // Row of A * Column of B
            }
            C[i * size + j] = temp;
        }
    }
}

// Square matrix multiplication on GPU : C = A * B
__global__ void matrix_mul_gpu(const float *A, const float *B, float *C, int size) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x; // Column index
    int idy = blockIdx.y * blockDim.y + threadIdx.y; // Row index

    if (idx < size && idy < size) {
        float temp = 0;
        for (int i = 0; i < size; i++) {
            temp += A[idy * size + i] * B[i * size + idx]; // Row of A * Column of B
        }
        C[idy * size + idx] = temp;
    }
}

int main() {
    float *h_A, *h_B, *h_C, *d_A, *d_B, *d_C;

    // Timing variables
    clock_t t0, t1, t2, t3;
    double t1sum = 0.0, t2sum = 0.0, t3sum = 0.0;

    // Start timing for initialization
    t0 = clock();

    // N*N matrices defined in 1 dimension
    h_A = new float[DSIZE * DSIZE];
    h_B = new float[DSIZE * DSIZE];
    h_C = new float[DSIZE * DSIZE];

    // Initialize the matrices
    for (int i = 0; i < DSIZE * DSIZE; i++) {
        h_A[i] = A_val;
        h_B[i] = B_val;
        h_C[i] = 0;
    }

    // Print A and B before multiplication
    printf("Matrix A (First 5x5 elements):");
    print_matrix(h_A, DSIZE, 5);
    printf("Matrix B (First 5x5 elements):");
    print_matrix(h_B, DSIZE, 5);

    // End initialization timing
    t1 = clock();
    t1sum = ((double)(t1 - t0)) / CLOCKS_PER_SEC;
    printf("Init took %f seconds. Begin compute\n", t1sum);

    // Allocate device memory
    cudaMalloc(&d_A, DSIZE * DSIZE * sizeof(float));
    cudaCheckErrors("Failed to allocate device memory for A");
    
    cudaMalloc(&d_B, DSIZE * DSIZE * sizeof(float));
    cudaCheckErrors("Failed to allocate device memory for B");
    
    cudaMalloc(&d_C, DSIZE * DSIZE * sizeof(float));
    cudaCheckErrors("Failed to allocate device memory for C");

    // Copy data from host to device
    cudaMemcpy(d_A, h_A, DSIZE * DSIZE * sizeof(float), cudaMemcpyHostToDevice);
    cudaCheckErrors("Failed to copy A to device");
    
    cudaMemcpy(d_B, h_B, DSIZE * DSIZE * sizeof(float), cudaMemcpyHostToDevice);
    cudaCheckErrors("Failed to copy B to device");

    // Specify block and grid dimensions
    dim3 block(16, 16);  // 16x16 threads per block
    dim3 grid((DSIZE + block.x - 1) / block.x, (DSIZE + block.y - 1) / block.y);

    // GPU matrix multiplication
    cudaEvent_t start, stop;
    float gpu_time = 0;
    
    // Start timing for GPU execution
    cudaEventCreate(&start);
    cudaEventCreate(&stop);
    cudaEventRecord(start);

    // Launch kernel
    matrix_mul_gpu<<<grid, block>>>(d_A, d_B, d_C, DSIZE);
    cudaCheckErrors("Kernel launch failed");

    // Stop GPU timing
    cudaEventRecord(stop);
    cudaEventSynchronize(stop);
    cudaEventElapsedTime(&gpu_time, start, stop);
    printf("GPU Compute took %f milliseconds\n", gpu_time);

    // Copy results back to host
    cudaMemcpy(h_C, d_C, DSIZE * DSIZE * sizeof(float), cudaMemcpyDeviceToHost);
    cudaCheckErrors("Failed to copy C to host");

    // End GPU timing
    t2 = clock();
    t2sum = ((double)(t2 - t1)) / CLOCKS_PER_SEC;
    printf("GPU Compute took %f seconds\n", t2sum);

    // Print C after GPU multiplication
    printf("Matrix C (First 5x5 elements) after GPU multiplication:");
    print_matrix(h_C, DSIZE, 5);

    // CPU matrix multiplication
    t3 = clock();
    matrix_mul_cpu(h_A, h_B, h_C, DSIZE);
    t3sum = ((double)(clock() - t3)) / CLOCKS_PER_SEC;
    printf("CPU Compute took %f seconds\n", t3sum);

    // Print C after CPU multiplication
    printf("Matrix C (First 5x5 elements) after CPU multiplication:");
    print_matrix(h_C, DSIZE, 5);

    // Free memory
    delete[] h_A;
    delete[] h_B;
    delete[] h_C;
    cudaFree(d_A);
    cudaFree(d_B);
    cudaFree(d_C);

    return 0;
}
